\usepackage{textcomp}\section{Massive Parallel Processing II: Spark}


\subsection{Map Reduce to DAG}
Directed acyclic graph. (causal dependency graph)

\subsection{RDD}
Resilient Distributed Dataset: BIG collection of anything (not necessarily a key-value pair), which is partitioned.
Resilient (dataset can be reproduced)

RDD lifecycle:
\begin{itemize}
    \item Creation: From HDFS, S3, Local file system, on the fly
    \item Transformation: Turn RDD into RDD (like map and reduce in map reduce but any transformation)
    \item Action: Output on screen, HDFS, S3, Local file system.
\end{itemize}
If I do not have an action, nothing is going to happen. Computation only get's triggered by Action.

\subsection{Execution}
\begin{itemize}
    \item use a shell (python or scala shell)
    \item Applications
\end{itemize}

\subsection{Transformation}
\begin{itemize}
    \item Filter: Order matters. function just says yes or no
    \item Map: for every input values output is one value
    \item flatmap: For every input value output is one, zero or more values. (close to map reduce map). loose information
    of origin of value.
    \item distinct: checks for equality of values only ouputs distinct values (spaghetti structure)
    \item sample: random filter
\end{itemize}
Transformation on 2 RDD:
\begin{itemize}
    \item Union: preserves order
    \item Intersection: Values that are in left and right rdd
    \item subtract: all values in left but not in right
    \item cartesion product: All possible pairs
\end{itemize}



\subsection{Action}
\begin{itemize}
    \item Collect: download everything on cluster and accumulated into local list on computer. only works
    if RDD is small enough.
    \item count: in parallel. Number of values
    \item count by value: number of same values returns small value pairs. If all values unique still huge output
    \item take: only downloads the first x values
    \item top: last x values
    \item takeSample: downloads random sample
    \item reduce: applies some binary operation on values. If operation commutative and associative can be done in parallel
    Here not pairs but single vaues (in contrast to map reduce)
\end{itemize}

\subsection{Pair RDDs}
\begin{itemize}
    \item Transformations (creates a new RDD from an existing one)
    \begin{itemize}
        \item keys
        \item values
        \item reduce by key (corresponds to reduce from map reduce): For every distinct key reduce function applied
        \item group by key: group key-value with same key \textrightarrow key with value being the list of values
        \item sort by key
        \item map values: applies function to every value in key-value pair. Don't care about keys.
        \item join: put together the keys that are the same.
        All the possible combination of the values. Cartesian product within the key.
        \item subtract by key: only return if key is not in the right one
    \end{itemize}
    \item Actions: compute result based on an RDD, either return to driver program or save it to an external storage system
    \begin{itemize}
        \item count by key
        \item lookup: value which is associated with specific key
    \end{itemize}
\end{itemize}

Three main differences to Map reduce:
\begin{itemize}
    \item values can be of any datatypes. don't need to use key-values in spark
    \item generic DAG
    \item More different transformation not just map and reduce
\end{itemize}


\subsection{Physical Layer of spark}
Parallel execution: default one task per hdfs block

Rdd1 \textrightarrow

\begin{itemize}
    \item Hierarchy: Machine, Executor (container), Core
    \item One container ((executor)) can have several tasks:
one core sequential execution of tasks. whenever one is finished gets next task. Cores in one executor share memory
    \item Parallelism is across cores. 1 Core = 1 slot.
    \item 1 task corresnponds to input parition: every value in a task is transformed sequentially.
    (several values per task). Same as in map reduce where several key-values are squentially processed in the same task.
    This is only possible for narrow dependency transformations.
    \item Can specifiy number of executors, memory per executors, etc: spark-submit --num-executors 42 --executor-memory 5GB
    --executor-cores 2 my-application.jar \textrightarrow 84 slots (tasks that can be executed in parallel)
\end{itemize}

\subsection{Terminology}
Narrow Dependency: Transaformations where data stays on same machine. Can spread all over cluster.
No comunication needed between machines. \\
Wide Dependency: one output needs whole input. \textrightarrow shuffle
Whenever there is shuffeling there is a new stage. (narrow dependency can squeez transformations into same stage)\\
\begin{itemize}
    \item Logical vertical grouping of narrow transformation into stages
    \item Stages are physically split into task.
    \item Sequence of stages is a Job.
\end{itemize}

\subsection{Performance}
\begin{itemize}
    \item Persisting RDD: if we want to reuse the output of a specific stage
    \item Avoid a wide dependency: pre-partitioning when you want to do a group by. Alrady have same group on same machine.
\end{itemize}

\subsection{DataFrames}
\begin{itemize}
    \item if values of RDD are a collection of rows \textrightarrow Dataframe. (keys only need to be stored once and is hence more compact)
    \item column storage of Dataframe: spark can drop columns if they are not needed in transformations
    \item spark will infer schema automatically when e.g. json input
    \item SparkSQl very similar to PostgressSQL
\end{itemize}

\subsubsection{Schema inference}
\begin{itemize}
    \item dataframe are more generic than tables (allow nestedness) but they need a schemas. They need to be validatable
    \item dataframe transformation can be used instead to use SQL (but transformations are not exactly the same as the RDD transformation.)
    gives you more control over the transformations.
    \item spakr will infer schema for csv, json etc. (will not always work)
    \item will not need to infrer schema for parquetn (since already inherent)
    \item can also connect to relational database and read other data format such as avro.
    \item datatypes: very similar to json, xml etc.
\end{itemize}

\subsection{Quizt}
1TB of json data with spark using RDD and pyspark. It is slow to execute:
\begin{itemize}
    \item use dataframe and SparkSQL
    \item Use parquet instead of json. Conversion done by either reading from json and write to parquet, spark will
    figure out schema. Other way: Rumble db and jsound (define schema)
\end{itemize}

\subsection{SparkSQLDialect}
\begin{itemize}
    \item sortby: sorts data only within partition
    \item distribute by country: all data with same country will end up on same machine
    \item or combination sortby and distribute by: cluster by (slightly less powerfull than order by since not overall sorted)
    \item groupby, orderby: need shuffles (wide transformations)
\end{itemize}


\subsection{Limits}
\begin{itemize}
    \item Nestedness: can use Explode to create duplicated row for every value in an array
    \item Heterogneity: if can't extrct data type will use a string.
\end{itemize}

\subsection{Quiz}
\begin{itemize}
    \item Let increase amount of data to petabytes. number of machines to thousands what start happening:
    A few nodes will keep taking significantly more time than average to complete the execution of their task.
    This is called tail latency.
    \item What is the issue with assigning one task to each slot (map reduce and spark): some task may take longer so that
    most slots will be idel waiting for the last one to complete.
    \item What do MapReduce 2 and Spark have in common: They are based on Yarn
    \item How does a document store likle MongoDB store documents physically: As an optimized binary form (BSON) on the
    local hard drive. JSON types arrays and objects are efficiently stored and basic atomic types are supported.
    Why Binary: Needs less space, can use compression. Less time to read from the disk.
    No repetetion of keys in parquet.
\end{itemize}


\subsection{Excercis08}
How to do count distinct key, since not possible to do in one map reduce job.
Use a reduce function that outputs keys but then still need to count those.
If you chain map reduce tasks, you are always writing and reading to/from disk \textrightarrow Spark with DAG
one spark job can have several map reduce operation without writing to disk \textrightarrow RDD
RDD are a immutable distributed colelction of objects.


\subsubsection{execution}
The following phases occur during Spark execution:
\begin{itemize}
    \item User code defines a DAG (directed acyclic graph) of RDDs. Operations on RDDs create new RDDs that refer back to their parents, thereby creating a graph.
    \item Actions force translation of the DAG to an execution plan. When you call an action on an RDD, it must be computed. This requires computing its parent RDDs as well.
    \item Spark's scheduler submits a job to compute all needed RDDs. That job will have one or more stages, which are parallel waves of computation composed of tasks. Each stage will correspond to one or more RDDs in the DAG. A single stage can correspond to multiple RDDs due to pipelining.
    \item Tasks are scheduled and executed on a cluster
    \item Stages are processed in order, with individual tasks launching to compute segments of the RDD. Once the final stage is finished in a job, the action is complete.
\end{itemize}




\section{Performance at Large Scale}
\subsection{sources of bottleneck}
\begin{itemize}
    \item memory
    \item cpu:
    \item disk I/O: map reduce and spark where created for this bottleneck.
    \item network IO (shuffling)
\end{itemize}

\subsubsection{latencies}
\begin{itemize}
    \item cpu: 1ns
    \item memory or : 100 of micro seconds
    \item reading from disk: mili seconds (up to 270 MB/s for SSD)
    \item network across continent: 100 of ms (up to 100 Gbits/s)
\end{itemize}


\subsubsection{Response time}
Total response time = Latency + Transfer

\begin{itemize}
    \item speedup = (respond_time_old/respnse_time_new)
    \item in reallity: speedup = $\frac{1}{1-p+\frac{p}{s}}$
    \begin{itemize}
        \item Ambdahl's law: percent parallelizable, speedup of 2 on parallelizable part. \textrightarrow speedup = 1.18 = $\frac{1}{a-0.3+\frac{0.3}{2}}$
        \item Gustafson's law: $Speedup= 1-p+sp$
    \end{itemize}
\end{itemize}


\subsubsection{spark tuning}
\begin{itemize}
    \item avodi memory scale-up: look for the classes athat are intitiated very often
    \item avoid cpu scale-up: search for gigantic for-loops (e.g map)
    \item avoid disk io scale-up: ue efficient format, compression
    \item Avoid network io scale-up: push down! pre-filter aggergate before, pre-project before shuffling.
    \item
\end{itemize}

One would not do 1 excecutor per machine but also not with each core = 1 executor but somewhwer in between.
I.e. 3 Excecutors with each 5 cores. anc 30GB of shared memory.
Rather than 15 executors with 1 core and 100/15GB of memory each.
Or 1 executor with 15 cores and 100GB of shared memory.

10 times more task than slots is optimial (so better distribution of tasks across slots) but not a lot more, since then latency increases as well

\subsubsection{relativistic effect}
1 slot will take an enourmous amount of time \textrightarrow tail latency
\begin{itemize}
    \item duplicate all your tasks. First done wins (hedge requests)
    \item deferred hedge requests: wait until one tasks takes much longer than expected than re-exicute on another machine
\end{itemize}



\section{Document Stores: NoSQL}
\begin{itemize}
    \item Tabular integrity = Relational integrity. domain integrity ensured by schemas.
    \item NosQL: can also  skip validation.
    \item Designed for collections of trees i.e. json or xml. Huge collection of small trees (one tree a few KB maybe a few MB)
    \item Are not good at doing joins but good at projection, selection and aggregation.
    \item Validation after data was populated
\end{itemize}

Bson binary encoding of JSON. Has added some datatypes: datetimes, objectID

\subsection{Querying a Document Store}


\begin{lstlisting}
    -Need to ETL data into database not a datalake.
    -API low level: Create read, update, delete (CRUD)
    -find() (Select *)
    -Filter: find({'key': value}) (Where key= values)
    -project: find({'key': 1})  or if you want to drop it find({'key': 0}) (Select key)
    -find({"$or": [{"key": value}, {"key": value}]})
    - query for a missing value: null (IS NULL)
\end{lstlisting}









